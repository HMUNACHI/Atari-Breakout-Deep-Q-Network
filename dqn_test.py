# -*- coding: utf-8 -*-
"""dqn_test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12eHT4IvgWYdq9n-f-E5yf95ZAQVpHLFs
"""

!pip install baselines

# TESTING
#from google.colab import drive
#drive.mount('/content/drive')
from baselines.common.atari_wrappers import make_atari, wrap_deepmind
import numpy as np
import tensorflow as tf
from tensorflow import keras
import gym

seed = 42
model = keras.models.load_model('/content/drive/MyDrive/deep_q_network')
env = make_atari("BreakoutNoFrameskip-v4")
env = wrap_deepmind(env, frame_stack=True, scale=True)
env.seed(seed)

env = gym.wrappers.Monitor(env, '/content/drive/MyDrive/video',
       video_callable=lambda episode_id :True, force=True)

n_episodes = 10 
returns = []
for _ in range(n_episodes): 
  ret=0
  state = np.array(env.reset())
  done = False 

  while not done :
    # FIXME: Incomplete
    # Use a greedy approach for exploration
    # Predict action Q-values
    # From environment state
    state_tensor = tf.convert_to_tensor(state)
    state_tensor = tf.expand_dims(state_tensor, 0)
    action_probs = model(state_tensor, training=False)
    # Take best action
    action = tf.argmax(action_probs[0]).numpy()

    # Apply the sampled action in our environment
    state_next, reward, done, _ = env.step(action)
    state_next = np.array(state_next)

    ret += reward

  returns.append(ret)

env.close()
print('Returns: {}'.format(returns))